open introduction.dmc

// ===================== MASTER CLASS IA =======================================

# Master Class IA

  ## Pour qui ?

  show info Toute personne intéressée par le sujet
  show info
    Pas de prérequis préalable mais mieux si:
      - Bases d'Algèbre Linéaire
      - Bases d'Analyse de Fonctions
      - Bases d'Algorithmie


  ## Pourquoi ?

  show info
    Invention majeure en informatique
    Secteur à fort potentiel d'investissement
  show info
    L'IA est présente partout et sa place dans la société ne va cesser d'augmenter
  show info
    Pour faire avancer le domaine plus rapidement, il y a un besoin de partage


  ## Quoi ?

  show info Introduction au Deep Learning
  show info
    Réseaux de Neurones Convolutifs
    Yolo & Transfert de Style
  show info
    Réseaux de Neurones Récurrents
    Embedding & Traduction
  show info
    Apprentissage par Réenforcement
    Deep Q Network & Améliorations
  show info
    Modèles génératifs
    Pokemon & Super Résolution

// ===================== IA ====================================================

# L'Intelligence Artificielle

  ## Définitions

  show info Il n'y a pas qu'une seule définition
  show info
    L'Intelligence Artificielle est la science dont le but est de faire faire par
    une machine des tâches que l'homme accomplit en utilisant son intelligence
  show info On parle plutôt d'Informatique Heuristique
  show quote from J.L.Laurière
    Etude des activités intellectuelles de l'homme pour lesquelles
    aucune méthode n'est à priori connue


  ## IA Faible vs IA Forte

    ### Faible
    show info Non-sensible, qui se concentre sur une tâche précise et prédéfinie

    ### Forte
    show info
      Capable de répondre à tout problème, non seulement de produire un comportement
      intelligent mais aussi d'éprouver une impression d'une réelle conscience
      de soi

// ===================== MATHS FOR DEEP LEARNING ===============================

# Mathématiques pour le Deep Learning

  ## Algèbre Linéaire


  ## Analyse de Fonctions

// ===================== PYTHON CHEAT SHEET ====================================

open cheat_sheet.py

# Python Cheat Sheet

  ## Types
  move to line 1
  show line 1 to 17
  move to line 2
  show line 2 to 5
  move to line 6
  show line 6 to 8
  move to line 9
  show line 9 to 10
  move to line 11
  show line 11 to 16
  move to line 17
  show line 17
  show line -1

  ## Containers
  move to line 19
  show line 19 to 23
  move to line 20
  show line 20
  move to line 21
  show line 21
  move to line 22
  show line 22
  move to line 23
  show line 23
  show line -1

  ## Variables
  move to line 25
  show line 25 to 35
  move to line 26
  show line 26 to 27
  move to line 28
  show line 28
  move to line 29
  show line 29
  move to line 30
  show line 30 to 33
  move to line 34
  show line 34
  move to line 35
  show line 35
  show line -1

  ## Convertions
  move to line 37
  show line 37 to 45
  show line -1

  ## Listes
  move to line 47
  show line 47 to 63
  move to line 48
  show line 48 to 49
  move to line 50
  show line 50 to 57
  move to line 58
  show line 58 to 63
  show line -1

  ## Conditions
  move to line 65
  show line 65 to 73
  show line -1

  ## Boucles
  move to line 75
  show line 75 to 81
  move to line 76
  show line 76 to 78
  move to line 80
  show line 80 to 81
  show line -1

  ## Fonctions
  move to line 83
  show line 83 to 88
  move to line 84
  show line 84 to 86
  move to line 88
  show line 88
  show line -1

  ## Classes
  move to line 90
  show line 90 to 112
  move to line 91
  show line 91 to 104
  move to line 106
  show line 106 to 107
  move to line 109
  show line 109 to 110
  move to line 112
  show line 112
  show line -1

  ## Imports
  move to line 114
  show line 114 to 117
  show line -1

  ## Ecriture et Lecture de Fichier
  move to line 119
  show line 119 to 127
  move to line 120
  show line 120 to 123
  move to line 125
  show line 125 to 127


open introduction.dmc

// ===================== DEEP LEARNING =========================================

# Introduction au Deep Learning

show info
  Le Deep Learning est l'apprentissage de Représentations
  Extracteur de caractéristique entraînable


    ## Machine Learning

      ### Régression Linéaire
      show maths y = W^{t}X
      show maths L(W, y_{i}, X_{i}) = \frac{1}{2} (y_{i}-W^{t}X_{i})^{2}
      show maths \frac{\partial L}{\partial W} = -(yi - W^{t}(t) X_{i}) X_{i}
      show maths W(t+1) = W(t) + \eta (t) (-\frac{\partial L}{\partial W})
      show info
        Minimiser la moyenne du coup
        Méthode du gradient stochastique
      show info
        Recherches dans les années 70 mais revenu au goût du jour
        Méthode imbattable en optimisation et seulement 3 lignes de code

      ### Perceptron
      show maths y = F(W^{t}X) \:\:\:\:\:\:\:\:\:\:\:\:\ F\,fonction\,seuil
      show maths L(W, y_{i}, X_{i}) = (F(W^{t}X_{i}) - y_{i}) W^{t} X_{i}
      show maths \frac{\partial L}{\partial W} = -(yi - F(W^{t}(t) X_{i})) X_{i}
      show maths W(t+1) = W(t) + \eta (t) (-\frac{\partial L}{\partial W})
      show info Régression Linéaire est un perceptron avec F = Id

      ### Régression Logistique
      show maths y = F(W^{t}X) \:\:\:\:\:\:\:\:\:\:\:\:\ F\,sigmoid
      show maths L(W, y_{i}, X_{i}) = 2log(1 + exp(y_{i}W^{t}X_{i}))
      show maths \frac{\partial L}{\partial W} = -(yi - F(W^{t}(t) X_{i})) X_{i}
      show maths W(t+1) = W(t) + \eta (t) (-\frac{\partial L}{\partial W})

    ## Limitations des Machines Linéaires
    show info
      La décision de surface est un Hyperplan de dimension N-1
      W est augmenté d'une dimension pour éviter de passer par l'origine
      Impossible de séparer certains ensembles par un hyperplan
    show quote from Thomas M. Cover
      A partir du moment où il y a plus de N points dans un espace à N dimensions,
      le probabilité de séparation devient de plus en plus faible


    ## Solutions

      show info Comment rendre un problème linéairement séparable ?

      ### Ruse
      show info Augmenter la dimension par une transformation non linéaire
      show info Exemple: Prendre le produit des entrées
      show maths
        (1, x_{1}, x_{2}): \, (1, x_{1}, x_{2}, x_{1}^{2}, x_{2}^{2}, x_{1}x_{2})
      show info
        La ligne de séparation devient conique
        Ne fonctionne pas à grande dimension, elle explose rapidement

      ### Autres Ruses
      show info Trop coûteux en terme de dimensionnalité

      ### Machines à Noyaux
      show info Machine à Vecteur de Support
      show maths F(X, W) = \sum_{k=1}^{P} W_{k} K(X, X_{k})
      show info
        La valeur est grande quand elle est proche et petite sinon
        Souvent un K est spécifique à un problème
        La méthode n'est donc pas généralisable

      ### Idées à retenir
      show info
        Les SVM sont performantes car le Noyau est surparamétrisé
        Cela rend le modèle assez flexible pour permettre l'apprentissage
        Il faudrait pénaliser le modèle pour pouvoir généraliser
      show quote from Vapnick - Chervonenkis
        La dimension de Vapnick d'un modèle de classification est le cardinal
        du plus grand ensemble pulvérisable par le modèle sans aucune erreur
      show maths
        Erreur + \sqrt{ \frac{ h(log(2N/h)+1) - log(\eta /4) }{ N } }
      show info Des features de meilleurs qualité entraînent de meilleurs résultats


    ## Réseaux de Neurones Profonds
    show info
      Combinaison de décisions élémentaires
      Les K sont appris par le modèle

      ### Aciennes Méthodes
      show info
        Prétraitement fixe
        Entraînement non supervisé pour augmenter la dimension de manière non linéaire et clairsemée
        Classifieur supervisé

      ### Nouvelles Méthodes
      show info Exactement la même sauf que chaque étape du processus est apprise
      show info
        Plus le modèle est profond plus les features sont de haut niveau
        Fonctionne car la nature est elle même compositionnelle
        C'est un Ensemble de concept divisés eux même en concepts plus simples
      show quote from Albert Einstein
        Ce qui est incompréhensible, c’est que le monde soit compréhensible.

      ### Challenges
      show info Apprendre des représentations du monde à plusieurs niveaux
      show info
        Exemple: Traitement visuel et audio chez les mamifères
        Ces traitements sont Feed-Forward

      ### Différents Types
      show info
        Feed-Forward: MLP, CNN, RNN
        Feed-Backward: DéConv, Génératife
        Bi-Directionnel: Deep Boltzman Machines, Stacked Auto Encoder

      ### Différents Entraînement
        #### Supervisé
        #### Non Supervisé
